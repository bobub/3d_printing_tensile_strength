{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Ensemble.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"PGyWbFv9MMAY"},"source":["# Individual Models"]},{"cell_type":"markdown","metadata":{"id":"ZDs7DtJyMMAZ"},"source":["## Pre-process"]},{"cell_type":"code","metadata":{"id":"MixpJyQqMMAZ","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1606505535614,"user_tz":-60,"elapsed":1329,"user":{"displayName":"Boris Bubla","photoUrl":"","userId":"03511421439649827085"}},"outputId":"a69d5e54-05cd-4285-e8c6-dba1f366c6de"},"source":["import utility\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","from sklearn.datasets import make_regression\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVR\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import RidgeCV\n","from sklearn.linear_model import Ridge\n","from sklearn.kernel_ridge import KernelRidge"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-50fbb6462599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utility'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"5pCtM0UxMMAa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7H119u7KMMAa"},"source":["## Data Generation via SMOTE-NC"]},{"cell_type":"code","metadata":{"id":"l_SoqWVuMMAa","outputId":"90ec9d8a-63ae-456c-dcc7-98bf11142a35"},"source":["# this cell just computes the possible train/test splits and looks at how they affect the quality of data generated\n","\n","splits = [0.1,0.2,0.25,0.3,0.4,0.5,0.6,0.7]\n","all_max_corr = []\n","all_mean_corr = []\n","\n","for split in splits:\n","\n","    # load and preprocess\n","    data = utility.load_and_preprocess('\\kaggle_dataset\\data.csv')\n","\n","    drop_variables = ['elongation','roughness','tension_strength']\n","    X = data.drop(drop_variables, axis=1)\n","    y = data['tension_strength']\n","    #print(X)\n","\n","    # Split data before data generation\n","\n","    #train test split\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=5)\n","    y_8 = y_train\n","    y_train = X_train.loc[:,'material_pla']\n","    X_train.loc[:,'material_pla'] = y_8\n","    X_train.rename(columns = {'material_pla': 'tension_strength'},inplace=True)\n","\n","    # use training data for generation\n","    X_gen, y_gen = utility.generate_data_smote(X=X_train, y=y_train, num_of_desired_samples=100) #desired samples per class \n","\n","    drop_variables = ['elongation','roughness','material_pla']\n","    X = data.drop(drop_variables, axis=1)\n","    X = pd.DataFrame(data=X.to_numpy())\n","    y = data['material_pla']\n","\n","    # evaluate quality of generation by comparing to distribution of entire dataset\n","\n","    max_corr, mean_corr = utility.evaluate_data_generation(X_orig=X, X_gen=X_gen, plot=False)\n","    \n","    all_max_corr.append(max_corr)\n","    all_mean_corr.append(mean_corr)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\Users\\Boris\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  self.obj[item] = s\n","C:\\Users\\Boris\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  return super(DataFrame, self).rename(**kwargs)\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"'SMOTENC' object has no attribute '_validate_data'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-bc6cd46a559a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# use training data for generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mX_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_data_smote\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_desired_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#desired samples per class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdrop_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'elongation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'roughness'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'material_pla'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Desktop\\Research Methodology and Scientific Writing\\3D printing dataset\\3d-printing-research-methodology\\utility.py\u001b[0m in \u001b[0;36mgenerate_data_smote\u001b[1;34m(X, y, num_of_desired_samples)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# 2. smote-nc to create new data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTENC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class012\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_class012\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \"\"\"\n\u001b[0;32m    903\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         )\n","\u001b[1;31mAttributeError\u001b[0m: 'SMOTENC' object has no attribute '_validate_data'"]}]},{"cell_type":"code","metadata":{"id":"m8bvlrxTMMAb"},"source":["#Visualise previous cell\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(splits,all_max_corr, label='Max absolute')\n","plt.plot(splits,all_mean_corr,label='Mean absolute')\n","plt.title('SMOTE data generation quality over different train/test splits')\n","plt.xlabel('Test data fraction of dataset')\n","plt.ylabel('Correlation difference')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOu3xWRFMMAb"},"source":["# USING BEST SPLIT:\n","\n","# load and preprocess\n","data = utility.load_and_preprocess('\\kaggle_dataset\\data.csv')\n","\n","drop_variables = ['elongation','roughness','tension_strength']\n","X = data.drop(drop_variables, axis=1)\n","y = data['tension_strength']\n","#print(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"swZgqgmKMMAb"},"source":["# Split data before data generation\n","\n","#train test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=101)\n","\n","# If using bootstrap uncomment\n","# drop_variables = ['elongation','roughness','tension_strength']\n","# X_test = data.drop(drop_variables, axis=1)\n","# y_test = data['tension_strength']\n","# X_train = X\n","# y_train = y\n","\n","\n","y_8 = y_train\n","y_train = X_train.loc[:,'material_pla']\n","X_train.loc[:,'material_pla'] = y_8\n","X_train.rename(columns = {'material_pla': 'tension_strength'},inplace=True)\n","print(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jug8pxquMMAc"},"source":["# use training data for generation\n","X_gen, y_gen = utility.generate_data_smote(X=X_train, y=y_train, num_of_desired_samples=100) #desired samples per class \n","\n","#print(X_gen)\n","\n","# original dataset\n","drop_variables = ['elongation','roughness','material_pla']\n","X_orig = data.drop(drop_variables, axis=1)\n","#X_orig = pd.DataFrame(data=X_orig.to_numpy())\n","#print(X_orig)\n","\n","\n","# evaluate quality of generation by comparing to distribution of entire dataset\n","\n","mean_corr_diff = utility.evaluate_data_generation(X_orig=X_orig, X_gen=X_gen)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JgQhMTBRMMAc"},"source":["# reformatting generated data into regression format\n","y_generated = X_gen[8]\n","X_gen[8]=y_gen\n","X_generated = X_gen\n","print(X_generated)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQbFAdgLMMAc"},"source":["# use the generated data to build models via CV\n","# use original data to evaluate model via .632 bootstrap\n","\n","y_train = y_generated\n","X_train = X_generated\n","\n","\n","mean_corr_diff = utility.evaluate_data_generation(X_orig=X_test, X_gen=X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YiZPB7YfMMAc"},"source":["print(type(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYI-vZ8aMMAc"},"source":["# normalise\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPo5aXBQMMAc"},"source":["## SVR Model"]},{"cell_type":"code","metadata":{"id":"3lUFXrD7MMAc"},"source":["# model/hyperparameter selection\n","\n","#parameter search - 5 fold cross validation\n","# C = 70 --> 100 samples\n","param_grid = {'C': [60], 'gamma': [0.3,0.2,0.1,0.01,0.001], 'kernel':['rbf','poly','sigmoid'] } \n","grid = GridSearchCV(SVR(),param_grid,refit=True,verbose=2, cv=5)\n","\n","#fit data to best model\n","grid.fit(X_train,y_train)\n","best_svr = grid.best_estimator_\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OygLVGE1MMAc"},"source":["# model evaluation - holdout test set\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","#bootstrap evaluation\n","\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n","print(best_svr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ZqWcYWlMMAc"},"source":["## Ridge Regression"]},{"cell_type":"code","metadata":{"id":"TtoUjT_DMMAc"},"source":["# model/hyperparameter selection\n","\n","#parameter search - uses 5 fold cv\n","grid = RidgeCV(alphas=[0.001,0.0001,0.01,0.05,0.1,0.15,0.2, 0.5], cv=5).fit(X_train, y_train)\n","\n","best_ridge = Ridge(alpha=grid.alpha_)\n","\n","print(best_ridge)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAA2Q8eQMMAc"},"source":["# model evaluation\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5m-659s2MMAc"},"source":["## Lasso Regression"]},{"cell_type":"code","metadata":{"id":"r3_a9krUMMAc"},"source":["# model/hyperparameter selection\n","from sklearn.linear_model import LassoCV\n","from sklearn.linear_model import Lasso\n","\n","\n","#parameter search - uses LOOCV\n","grid = LassoCV(alphas=[0.01,0.05,0.001,0.005,0.0001,0.1,0.3,0.31,0.32,0.33,0.34,0.5]).fit(X_train, y_train)\n","\n","best_lasso = Lasso(alpha=grid.alpha_)\n","print(best_lasso)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xG7sG5xOMMAc"},"source":["# model evaluation\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1P3umyJpMMAc"},"source":["## Elastic Net regression"]},{"cell_type":"code","metadata":{"id":"zllOEVbEMMAc"},"source":["# model/hyperparameter selection\n","from sklearn.linear_model import ElasticNetCV\n","from sklearn.linear_model import ElasticNet\n","\n","\n","#parameter search - uses 5 fold cv\n","grid = ElasticNetCV(l1_ratio=[0.7,0.9,0.95,0.99,0.999],alphas=[0.4,0.5,0.55,0.6,0.65,0.7,0.8,0.9], cv=5).fit(X_train, y_train)\n","\n","best_elastic = ElasticNet(alpha=grid.alpha_, l1_ratio=grid.l1_ratio_)\n","\n","print(grid.alpha_)\n","print(grid.l1_ratio_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wR6UDfpiMMAc"},"source":["# model evaluation\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V_TMoQnEMMAc"},"source":["## Kernel Ridge Regression"]},{"cell_type":"code","metadata":{"id":"ajoi9NmsMMAc"},"source":["# model/hyperparameter selection\n","\n","#parameter search - 5 fold cross validation\n","# alpha = 0.2 --->100\n","param_grid = {'alpha': [0.2], 'gamma': [0.3,0.2,0.1,0.05], 'kernel':['rbf','poly','sigmoid'], 'degree':[1,2,3]} \n","grid = GridSearchCV(KernelRidge(),param_grid,refit=True,verbose=2)\n","\n","#fit data to best model\n","grid.fit(X_train,y_train)\n","best_krr = grid.best_estimator_\n","print(best_krr)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"subJtB4eMMAc"},"source":["# model evaluation\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jiQjCXfNMMAc"},"source":["## Random Forests Regressor"]},{"cell_type":"code","metadata":{"id":"-JAPBb6OMMAd"},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","#parameter search - 5 fold cross validation\n","param_grid = {'max_depth': [2,3,4,5,6,7,8,9,10], 'min_samples_split': [2,3]} \n","grid = GridSearchCV(RandomForestRegressor(random_state=0,bootstrap=True),param_grid,refit=True,verbose=2)\n","\n","#fit data to best model\n","grid.fit(X_train,y_train)\n","best_forest = grid.best_estimator_\n","print(best_forest)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ebg8jAt_MMAd"},"source":["# model evaluation\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"plHKsFG-MMAd"},"source":["## MLP Regressor - not enough data to get meaningful results"]},{"cell_type":"code","metadata":{"id":"EeQMlZxzMMAd"},"source":["\n","# model/hyperparameter selection\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {'hidden_layer_sizes':[[5,10,10,1],[4,8,4,1],[2,3,6,1],[2,4,5,1],[2,20,20,1],[2,10,20,1],[5,5,5,5,1],[5,5,5,5,5,1],[8,7,6,5,4,3,2,1]], 'alpha':[1],'learning_rate_init':[0.01],'momentum':[0.2]}\n","\n","#parameter search - 5 fold cross validation \n","grid = GridSearchCV(MLPRegressor(batch_size=10,max_iter=1000, random_state =5, early_stopping=True), param_grid, refit=True, verbose=2, cv=3)\n","\n","#fit data to best model\n","grid.fit(X_train,y_train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KP6PGs9MMAd"},"source":["# model evaluation\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p71nE8NKMMAd"},"source":["best_mlp= grid.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"co_GPUsVMMAd"},"source":["# Ensemble Models"]},{"cell_type":"markdown","metadata":{"id":"FGkhQFI4MMAd"},"source":["## Adaboosting - just makes models overfit on training data, no real performance advantage"]},{"cell_type":"code","metadata":{"id":"xA5j1BdeMMAd"},"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import AdaBoostRegressor\n","\n","boosted_models = []\n","estimators = [best_svr, best_krr, best_elastic, best_lasso, best_ridge, best_forest]\n","\n","for e in estimators:\n","    \n","    #adaboost using svm model as base\n","    model =  AdaBoostRegressor(base_estimator=e,random_state=0,n_estimators=50)\n","\n","    #parameter search - 5 fold cross validation\n","    param_grid = {'learning_rate':[0.05,0.1,0.15,0.2]} \n","    grid = GridSearchCV(model,param_grid,refit=True, cv=5, verbose=2)\n","\n","    #fit data to best model\n","    grid.fit(X_train,y_train)\n","    \n","    boosted_models.append(grid.best_estimator_)\n","\n","    # model evaluation\n","\n","    #make predictions on test data\n","    y_test_pred = grid.predict(X_test)\n","    y_train_pred = grid.predict(X_train)\n","\n","\n","    print('Train Results:\\n')\n","    train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","    #plot predictions\n","    print('\\nTest Results:\\n')\n","    test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rUdV7fK3MMAd"},"source":["## Bagging - simple average"]},{"cell_type":"code","metadata":{"id":"sOQSw97SMMAd"},"source":["from sklearn.ensemble import BaggingRegressor\n","grid = BaggingRegressor(base_estimator=best_svr, n_estimators=10, random_state=0).fit(X_train, y_train)\n","\n","#make predictions on test data\n","y_test_pred = grid.predict(X_test)\n","y_train_pred = grid.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"euWlzvueMMAd"},"source":["## Stacking - helps significantly when best 3 models are used: svr, krr, forest\n","\n","## Currently the best model"]},{"cell_type":"code","metadata":{"id":"ThLZyaXJMMAd"},"source":["from sklearn.ensemble import StackingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","estimators = [ ('svr', best_svr),('krr',best_krr) ,('forest',best_forest), ('mlp', best_mlp)]\n","\n","reg = StackingRegressor(estimators=estimators).fit(X_train, y_train)\n","\n","#reg.fit(X_train,y_train)\n","#print(reg.final_estimator.predict(X_test))\n","\n","#make predictions on test data\n","y_test_pred = reg.predict(X_test)\n","y_train_pred = reg.predict(X_train)\n","\n","\n","print('Train Results:\\n')\n","train_mape, train_rmse, train_r2 = utility.evaluate(y_train_pred, y_train, plot=False)\n","\n","#plot predictions\n","print('\\nTest Results:\\n')\n","test_mape, test_rmse, test_r2= utility.evaluate(y_test_pred, y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IERrRoc8MMAd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pp4KkidJMMAd"},"source":[""],"execution_count":null,"outputs":[]}]}